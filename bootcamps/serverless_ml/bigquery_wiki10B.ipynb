{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bigquery_wiki10B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PDDqFd8hon3v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Experiment with BigQuery API</h1>\n",
        "\n",
        "In this notebook, you will be trying out BigQuery and its Application Programming Interface (API) to analyze a dataset of 10 billion Wikipedia articles from 2014.  To be precise, the table with the articles consists of 10,677,046,566 rows or 692.58 GB of data, including the date/timestamp with the last modification to the article, as well as its title, language, and total number of views at that timestamp.\n",
        "\n",
        "---\n",
        "Before you start, **make sure that you are logged in with your student account**. Otherwise you may incur Google Cloud charges for using this notebook. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "To confirm that you are logged in with your student account, check that you see a letter S in a circle located in the upper right hand corner of this notebook line in the screenshot below. Of course the color around your letter S might not be exactly the same ;)\n",
        "\n",
        "If you are not sure if you are logged in with your student account, close all your private (i.e. incognito/anonymous) windows, open a new one,  log in [here](https://console.cloud.google.com) using the student credentials you got earlier, and finally return back to this page to continue with the notebook.\n",
        "\n",
        "![](https://i.imgur.com/PfSHVAb.png)"
      ]
    },
    {
      "metadata": {
        "id": "G9rUnVxslfTX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[](https://i.imgur.com/5D6SJcu.png)"
      ]
    },
    {
      "metadata": {
        "id": "Wq75B91eon3y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import shutil\n",
        "from google.cloud import bigquery\n",
        "\n",
        "#@markdown Copy-paste your GCP Project ID in the following field:\n",
        "\n",
        "PROJECT = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Next, use Shift-Enter to run this cell and to complete authentication.\n",
        "\n",
        "try:  \n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()  \n",
        "  print(\"AUTHENTICATED\")\n",
        "except:\n",
        "  print(\"FAILED to authenticate\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJ2yoW-hon39",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Extract sample data from BigQuery </h3>\n",
        "\n",
        "Here's a SQL query to sample 10 rows of data. The SQL statement uses the LIMIT keyword to restrict the sample size to 10 rows. Since the ORDER BY clause precedes the LIMIT keyword, you are guaranteed to receive the rows in the descending order by the number of article views. Notice that the code in the next cell is using BigQuery APIs to execute the SQL statement and then stores the response in a Pandas dataframe variable named `trips`."
      ]
    },
    {
      "metadata": {
        "id": "t9xPjpPDpQGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create a BigQuery API client\n",
        "bq = bigquery.Client(project=PROJECT)\n",
        "\n",
        "#configure the client to ignore cached results ;)\n",
        "job_config = bigquery.QueryJobConfig()\n",
        "job_config.use_query_cache = False\n",
        "\n",
        "#start the query timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "#send the SQL statement to BigQuery,\n",
        "#get the result back, and prepare it\n",
        "#as a nice looking Python Pandas data frame\n",
        "trips = bq.query('''\n",
        "  SELECT \n",
        "      language, title, SUM(views) as views \n",
        "\n",
        "  FROM `bigquery-samples.wikipedia_benchmark.Wiki10B`Â \n",
        "\n",
        "  WHERE \n",
        "   title LIKE '%Google%'\n",
        "\n",
        "  GROUP BY language, title\n",
        "\n",
        "  ORDER BY views DESC \n",
        "\n",
        "  LIMIT 10\n",
        "  ''', job_config=job_config).to_dataframe()\n",
        "\n",
        "#print how much time passed\n",
        "print(datetime.datetime.now() - start)\n",
        "\n",
        "#render the result\n",
        "trips"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm7TZtVAiCE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Recap </h3>\n",
        "\n",
        "In this sample notebook, you ran a benchmark query against the BigQuery serverless data warehouse. After the BigQuery APIs returned the results, you learned about the amount of time it took to execute the query and you observed the results with the most viewed articles about Google. You also learned how to run use BigQuery Python API client and how to enable or disable query result cache. The following screenshot illustrates the result you should have receved in the previous step.\n",
        "\n",
        "![](https://i.imgur.com/ljEu9yS.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "HVuX8oeMon5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Counter Factual .AI LLC.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}