{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traineval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XK6pRemnQNX4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Robust training and monitoring </h1>\n",
        "\n",
        "In this notebook, you will refactor the code to call ```train_and_evaluate``` method instead of hand-coding the evaluation of the machine learning pipeline. This ensures that the evaluation is done as part of the training process instead of as a separate step. It also adds in failure-handling that is necessary for robust  distributed training capabilities.\n",
        "\n",
        "Finally, you will use TensorBoard to monitor the training.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Before you start, **make sure that you are logged in with your student account**. Otherwise you may incur Google Cloud charges for using this notebook. \n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ma1hwt5BQNX9",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "print tf.__version__\n",
        "\n",
        "#@markdown Remember to uncheck \"Reset all runtimes before running\"\n",
        "\n",
        "#@markdown As you know, reseting the runtime will delete any files you may have on your notebook file system. \n",
        "#@markdown ![](https://i.imgur.com/9dgw0h0.png)\n",
        "\n",
        "# Copy taxi-*.csv files from github if they are missing from the runtime.\n",
        "!wget --quiet -nc https://github.com/osipov/training-data-analyst/raw/master/bootcamps/serverless_ml/taxi-11k-datasets.zip  \n",
        "!unzip -q -n taxi-11k-datasets.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5o-PyS0OQNYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Input </h2>\n",
        "\n",
        "Continue reading the data using the `read_dataset` method implemented in the earlier lab. Recall that this implementation is reading data in batches. Instead of using Pandas Dataframes, the method is using `tf.data.TextLineDataset` from the TensorFlow Datasets API."
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "nhPh2A8IQNYD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
        "LABEL_COLUMN = 'fare_amount'\n",
        "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
        "\n",
        "def read_dataset(filename, mode, batch_size = 512):\n",
        "  def _input_fn():\n",
        "    def decode_csv(value_column):\n",
        "      columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
        "      features = dict(zip(CSV_COLUMNS, columns))\n",
        "      label = features.pop(LABEL_COLUMN)\n",
        "      return features, label\n",
        "    \n",
        "    # Create list of files that match pattern\n",
        "    file_list = tf.gfile.Glob(filename)\n",
        "\n",
        "    # Create dataset from file list\n",
        "    dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        num_epochs = None # indefinitely\n",
        "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
        "    else:\n",
        "        num_epochs = 1 # end-of-input after this\n",
        " \n",
        "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UJ63oQqOQNYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Create features out of input data </h2>\n",
        "\n",
        "For now, pass these through as in the earlier lab."
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "czpleIgHQNYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_COLUMNS = [\n",
        "    tf.feature_column.numeric_column('pickuplon'),\n",
        "    tf.feature_column.numeric_column('pickuplat'),\n",
        "    tf.feature_column.numeric_column('dropofflat'),\n",
        "    tf.feature_column.numeric_column('dropofflon'),\n",
        "    tf.feature_column.numeric_column('passengers'),\n",
        "]\n",
        "\n",
        "def add_more_features(feats):\n",
        "  # Nothing to add (yet!)\n",
        "  return feats\n",
        "\n",
        "feature_cols = add_more_features(INPUT_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "jhpO9rzRQNYI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> train_and_evaluate </h2>\n",
        "\n",
        "Recall that the `serving_input_fn` is needed to define a prediction interface to your Estimator API based model. This function is used during the evaluation of the model. It will also be used in a later lab by a model that you will deploy into production. The feature placeholders define names and data types for each feature. \n",
        "\n",
        "The `features` dictionary provides support for predicting with the model over batches of evaluation and test examples."
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rCS2XeHKQNYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_fn():\n",
        "  feature_placeholders = {\n",
        "    'pickuplon' : tf.placeholder(tf.float32, [None]),\n",
        "    'pickuplat' : tf.placeholder(tf.float32, [None]),\n",
        "    'dropofflat' : tf.placeholder(tf.float32, [None]),\n",
        "    'dropofflon' : tf.placeholder(tf.float32, [None]),\n",
        "    'passengers' : tf.placeholder(tf.float32, [None]),\n",
        "  }\n",
        "  #tf.expand_dims inserts a batch dimensions before\n",
        "  #the feature values, so that it is possible \n",
        "  #to classify multiple rows of feature values as a batch\n",
        "  features = {\n",
        "      key: tf.expand_dims(tensor, -1)\n",
        "      for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "  \n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OpWEgBiUQNYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, num_train_steps):\n",
        "  estimator = tf.estimator.LinearRegressor(\n",
        "                       model_dir = output_dir,\n",
        "                       feature_columns = feature_cols)\n",
        "  \n",
        "  train_spec=tf.estimator.TrainSpec(\n",
        "                       input_fn = read_dataset('./taxi-train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
        "                       max_steps = num_train_steps)\n",
        "  \n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  \n",
        "  eval_spec=tf.estimator.EvalSpec(\n",
        "                       input_fn = read_dataset('./taxi-valid.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
        "                       steps = None,\n",
        "                       start_delay_secs = 1, # start evaluating after N seconds\n",
        "                       throttle_secs = 10,  # evaluate every N seconds\n",
        "                       exporters = exporter)\n",
        "  \n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "x8eEMpsmQNYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run training    \n",
        "OUTDIR = 'taxi_trained'\n",
        "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
        "train_and_evaluate(OUTDIR, num_train_steps = 5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "35DHz2CyQNYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Monitoring with TensorBoard </h2>"
      ]
    },
    {
      "metadata": {
        "id": "dbUEBAjfQyXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboard==1.13.0\n",
        "%load_ext tensorboard.notebook "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qAzYWpxFQ0kY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown Run this cell to start TensorBoard.\n",
        "\n",
        "#@markdown Once the TensorBoard comes up, put this cell in focus, click on the vertical ellipsis in the upper right of this cell, and choose view output full screen.\n",
        "%tensorboard --logdir $OUTDIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5Mv6TQkTQNYb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Counter Factual. AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
      ]
    }
  ]
}