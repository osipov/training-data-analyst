{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mle_deploy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AHJIrdDaUxaA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Deploying a TensorFlow model to Cloud MLE</h1>\n",
        "\n",
        "In this notebook, you will take a TensorFlow model that was trained using Cloud MLE and turn it into an Application Programming Interface (API) deployed to and hosted by Cloud MLE engine. This will ensure that your model is available to developers worldwide. You will also review how Cloud MLE monitors access to your model API so you can measure its popularity and performance.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Before you start, **make sure that you are logged in with your student account**. Otherwise you may incur Google Cloud charges for using this notebook. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Also, remember to uncheck \"Reset all runtimes before running\" when executing the next cell.\n",
        "\n",
        "Reseting the runtime will delete any files you may have on your notebook file system. \n",
        "\n",
        "![](https://i.imgur.com/9dgw0h0.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "DQXV2gT2VJKb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown Copy-paste your GCP Project ID in the following field:\n",
        "\n",
        "PROJECT = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Next, use Shift-Enter to run this cell and complete authentication.\n",
        "\n",
        "try:  \n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()  \n",
        "  print(\"AUTHENTICATED\")\n",
        "except:\n",
        "  print(\"FAILED to authenticate\")\n",
        "\n",
        "#Modify the following to use a different bucket and/or region\n",
        "#for Google Cloud Storage and for Cloud MLE\n",
        "BUCKET = PROJECT  \n",
        "REGION = \"us-central1\"  \n",
        "\n",
        "# Copy taxi-*.csv files from github if they are missing from the runtime.\n",
        "!wget --quiet -nc https://github.com/osipov/training-data-analyst/raw/master/bootcamps/serverless_ml/taxi-11k-datasets.zip\n",
        "!unzip -q -n taxi-11k-datasets.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "whg5OwvWp4vj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for bash\n",
        "import os\n",
        "os.environ['PROJECT'] = PROJECT\n",
        "os.environ['BUCKET'] = BUCKET\n",
        "os.environ['REGION'] = REGION\n",
        "os.environ['TF_VERSION'] = '1.12'  # Tensorflow version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oJbJ81Swp4b7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud config set project $PROJECT\n",
        "gcloud config set compute/region $REGION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7naoQS2unCMc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Use TensorBoard to monitor the model located on Google Cloud Storage</h1>"
      ]
    },
    {
      "metadata": {
        "id": "01sFKqP-UxaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall that Cloud MLE saves a trained model as a collection of checkpoint files on in a Google Cloud Storage bucket. Open the [Jobs](https://console.cloud.google.com/mlengine/jobs) section of the MLE user interface to confirm that the training job is done or is close to being done. You can't deploy a model as an API util MLE finishes training. \n",
        "\n",
        "Run the next cell to start TensorBoard and to confirm that the model was trained as expected."
      ]
    },
    {
      "metadata": {
        "id": "54xj8SmIp_nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboard==1.13.0\n",
        "%load_ext tensorboard.notebook "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPyAwPOvqB3c",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "OUTDIR=\"gs://{}/taxifare/11k/taxi_trained\".format(BUCKET)\n",
        "\n",
        "#@markdown Once the TensorBoard comes up, put this cell in focus, click on the vertical ellipsis in the upper right of this cell, and choose view output full screen.\n",
        "%tensorboard --logdir $OUTDIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDLEErUFq-ZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you look closely and compare the global steps / second metric for Cloud MLE against what you have seen with Colab, you will notice that Cloud MLE is about half as fast as Colab. This is because you were using the BASIC scale tier in Cloud MLE during training. When running in production, it is easy to modify the scale tier and allocate a larger server or even a server cluster to train your model. The custom training clusters available in Cloud MLE can be more powerful than individual CPUs, GPUs, or even TPUs training in Colab."
      ]
    },
    {
      "metadata": {
        "id": "Cf_VgEd4UxbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Deploy the model </h2>\n",
        "\n",
        "List the files in the storage bucket subdirectory where the trained model was saved and use it to deploy the model. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "psX6hjliNhp5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gsutil ls gs://${BUCKET}/taxifare/11k/taxi_trained/export/exporter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ghy1TAgytBOp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the environment variables using `os.environ` so that you can reuse them across multiple bash code cells."
      ]
    },
    {
      "metadata": {
        "id": "qVChfDauMaJ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['MODEL_NAME'] = \"taxifare\"\n",
        "os.environ['MODEL_VERSION'] = \"v1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvdAP9BdtJpE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use `gcloud` to deploy the model. This involves creating a deployed model as a model version in Cloud MLE. Keep in mind that deploying a model will take up to <b>5 minutes</b>."
      ]
    },
    {
      "metadata": {
        "id": "zc3gpHmaUxbW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/taxifare/11k/taxi_trained/export/exporter | tail -1)\n",
        "\n",
        "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
        "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
        "#gcloud ml-engine models delete ${MODEL_NAME}\n",
        "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
        "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version ${TF_VERSION}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvv0oviZtZxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While the previous cell is still running, you can monitor the deployment progress in the [Models](https://console.cloud.google.com/mlengine/models) section of the Cloud MLE dashboard. You will need to click on `taxifare` once it becomes available in the list of the models. After the deployment finishes, you will be able to open the `v1` version of the taxifare model.\n",
        "\n",
        "<h3>Do not proceed until you can confirm that the last cell finished deploying the model</h3>"
      ]
    },
    {
      "metadata": {
        "id": "VtNoxFGJUxbY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Prediction </h2>"
      ]
    },
    {
      "metadata": {
        "id": "flP2fPIOt35u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's create a local file to test out the deployed model. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mpczopFfNTmC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile ./test.json\n",
        "{\"pickuplon\": -73.885262,\"pickuplat\": 40.773008,\"dropofflon\": -73.987232,\"dropofflat\": 40.732403,\"passengers\": 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pogp4HRkuA8p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start by getting a prediction from your model using the `gcloud` command:"
      ]
    },
    {
      "metadata": {
        "id": "6fhDlnykUxbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud ml-engine predict --model=${MODEL_NAME} --version=${MODEL_VERSION} --json-instances=./test.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7X2h8onauGoC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once you can see that the API returned a prediction, recall that that `gcloud` command requires the Google Cloud SDK. This is too complex for many applications. Instead, you can give application developers the code snippet from the next cell. Using this code, they will be able to use your model API from any Python program. Try it yourself:"
      ]
    },
    {
      "metadata": {
        "id": "-nbbIUwuUxbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient import discovery\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import json\n",
        "\n",
        "credentials = GoogleCredentials.get_application_default()\n",
        "api = discovery.build('ml', 'v1', credentials=credentials,\n",
        "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
        "\n",
        "request_data = {'instances':\n",
        "  [\n",
        "      {\n",
        "        'pickuplon': -73.885262,\n",
        "        'pickuplat': 40.773008,\n",
        "        'dropofflon': -73.987232,\n",
        "        'dropofflat': 40.732403,\n",
        "        'passengers': 2,\n",
        "      }\n",
        "  ]\n",
        "}\n",
        "\n",
        "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'taxifare', 'v1')\n",
        "response = api.projects().predict(body=request_data, name=parent).execute()\n",
        "print \"response={0}\".format(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwqYlov_vlK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, if you return to the [Cloud MLE](https://console.cloud.google.com/mlengine/models/taxifare/versions/v1) user interface for the `taxifare/v1`, you should be able to monitor various metrics gathered by Cloud MLE, including number of predictions/second, model response latency, and others."
      ]
    },
    {
      "metadata": {
        "id": "2ii3FSa2u7IY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Recap</h2>\n",
        "\n",
        "In this notebook, you used TensorBoard to confirm that a Cloud MLE training job started in an earlier lab  finished training a model. You also checked that the model files have been saved to a Google Cloud Storage bucket. \n",
        "\n",
        "Next, you used the model files from the bucket and deployed them as an API on Cloud MLE. After this, you were able to use the model hosted on Cloud MLE as an API to get back predictions from bash command line (using gcloud) and from a Python runtime."
      ]
    },
    {
      "metadata": {
        "id": "yLup-4j7Uxbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Counter Factual .AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
      ]
    }
  ]
}