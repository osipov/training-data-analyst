{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_layers_dnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vEeJQT4RLvQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Lab Exercise: Fashion MNIST Image Classification with tf.layers API\n",
        "\n",
        "This notebook demonstrates how to train a deep neural network model for image classification and to use TensorBoard to explore the training loss function, check model accuracy on a test dataset, and visualize the TensorFlow computational graph."
      ]
    },
    {
      "metadata": {
        "id": "9fr0-m0OLvQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DO NOT CHANGE THIS CELL\n",
        "import os\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "MODEL_TYPE='dnn'       # deep neural network\n",
        "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
        "\n",
        "#required to start / stop TensorBoard in Colab\n",
        "def start_tensorboard(logdir, url_file):\n",
        "  get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(logdir))\n",
        "  get_ipython().system_raw('lt --port 6006 >> {} 2>&1 &'.format(url_file))\n",
        "  get_ipython().system('cat {}'.format(url_file))\n",
        "\n",
        "def stop_tensorboard(url_file):\n",
        "  get_ipython().system_raw(\"ps -Af  | grep -E 'tensorboard|lt --port' | awk '{print $2}' | xargs -I % kill -9 %\")\n",
        "  get_ipython().system_raw(\"rm {}\".format(url_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aToqKWsjso6Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a Python module\n",
        "\n",
        "Evaluate the next cell to git clone the Python package with the code for this lab. Notice that the package is stored in the `fashionmodel` directory, following the conventions for a Python package structure and the separation into `task.py` and `model.py` files.\n",
        "\n",
        "The  `model.py` and `task.py` files containing the  code are in <a href=\"fashionmodel/trainer\">fashionmodel/trainer</a>"
      ]
    },
    {
      "metadata": {
        "id": "pnvI4YTaLvQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/osipov/training-data-analyst.git\n",
        "cp -r training-data-analyst/bootcamps/imagereco/fashionmodel .\n",
        "find fashionmodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiwZQaA_LvQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TODO: Before you execute the next cell,  add the 3rd dense layer in the body of the `dnn_model` method**\n",
        "\n",
        "Recall that tf.layers API provides a pre-built implementations of fully connected (dense) layers. Complete the implementation of the `dnn_model` following the instruction in the TODO of the code snippet below. After you complete the TODO and evaluate the next cell, the `model.py` file will be updated to use your implementation during model training."
      ]
    },
    {
      "metadata": {
        "id": "sz_wQQJ1lJdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile fashionmodel/trainer/model.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# Licensed under the Apache License, Version 2.0 See footer for details.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "HEIGHT=28\n",
        "WIDTH=28\n",
        "NCLASSES=10\n",
        "\n",
        "def dnn_model(img, mode, hparams):\n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) #flatten input\n",
        "  \n",
        "  h1 = tf.layers.dense(X, 100, activation=tf.nn.relu)\n",
        "  \n",
        "  h2 = tf.layers.dense(h1, 100, activation=tf.nn.relu)\n",
        "  \n",
        "  #TODO: declare a tf.layers.dense layer as a variable named h3.\n",
        "  #The layer should take h2 as input, contain 100 neurons,\n",
        "  #and use the tf.nn.relu activation function \n",
        "  \n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def train_and_evaluate(output_dir, hparams):\n",
        "  EVAL_INTERVAL = 60\n",
        "\n",
        "  (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "  train_images = train_images.astype(dtype=np.float32, copy=False).reshape(train_images.shape + (1,))\n",
        "  test_images = test_images.astype(dtype=np.float32, copy=False).reshape(test_images.shape + (1,))\n",
        "  train_labels = np.eye(10)[train_labels]\n",
        "  test_labels = np.eye(10)[test_labels]    \n",
        "    \n",
        "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image': train_images},\n",
        "    y=train_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True,\n",
        "    queue_capacity=6000\n",
        "  )\n",
        "\n",
        "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':test_images},\n",
        "    y=test_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        "    queue_capacity=6000\n",
        "  )\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
        "                                     params = hparams,\n",
        "                                     config=tf.estimator.RunConfig(\n",
        "                                         save_checkpoints_secs = EVAL_INTERVAL),\n",
        "                                     model_dir = output_dir)\n",
        "  \n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
        "                                    max_steps = hparams['train_steps'])\n",
        "  \n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  \n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
        "                                  steps = None,\n",
        "                                  exporters = exporter,\n",
        "                                  throttle_secs = EVAL_INTERVAL)\n",
        "  \n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "  \n",
        "def serving_input_fn():\n",
        "    #input will be rank 3\n",
        "    feature_placeholders = {\n",
        "        'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
        "    \n",
        "    #but model function requires rank 4\n",
        "    features = {\n",
        "        'image': tf.expand_dims(feature_placeholders['image'], -1)} \n",
        "    \n",
        "    return tf.estimator.export.ServingInputReceiver(features, \n",
        "                                                    feature_placeholders)\n",
        "\n",
        "def image_classifier(features, labels, mode, params):\n",
        "  model_functions = {\n",
        "      'dnn':dnn_model}\n",
        "  \n",
        "  model_function = model_functions[params['model']]  \n",
        "  \n",
        "  ylogits, nclasses = model_function(features['image'], mode, params)\n",
        "\n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  \n",
        "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=ylogits, labels=labels))\n",
        "    \n",
        "    evalmetrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # this is needed for batch normalization, but has no effect otherwise\n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "         train_op = tf.contrib.layers.optimize_loss(\n",
        "             loss, \n",
        "             tf.train.get_global_step(),\n",
        "             learning_rate=params['learning_rate'], \n",
        "             optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "      \n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        " \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={'classes':tf.estimator.export.PredictOutput(\n",
        "            {\"probabilities\": probabilities, \"classes\": classes})}\n",
        "    )\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSzWpku4LvQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf fashion_trained\n",
        "export PYTHONPATH=${PYTHONPATH}:${PWD}/fashionmodel\n",
        "python -m trainer.task \\\n",
        "   --output_dir=${PWD}/fashion_trained/${MODEL_TYPE} \\\n",
        "   --train_steps=600 \\\n",
        "   --learning_rate=0.01 \\\n",
        "   --train_batch_size=100 \\\n",
        "   --model=$MODEL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USDJ8fRQLvQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training should finish in just a few seconds and save the model checkpoint and training metadata to a `fashion_trained/dnn` directory. Next, you will explore the training metrics using TensorBoard."
      ]
    },
    {
      "metadata": {
        "id": "cMi3UKzrFt56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitoring training with TensorBoard\n",
        "\n",
        "Execute the next cell to start the TensorBoard process, then use the link from the output to open TensorBoard UI in a new tab."
      ]
    },
    {
      "metadata": {
        "id": "-B17C-a1LvQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "start_tensorboard('./fashion_trained/{}'.format(MODEL_TYPE), 'url')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtsxDW_yOBIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%sx read -p 'Press Enter in the input box to stop TensorBoard '\n",
        "stop_tensorboard('url')\n",
        "print(\"Stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ik-w03A6LvRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "</pre>"
      ]
    }
  ]
}