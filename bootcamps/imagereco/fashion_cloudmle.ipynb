{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_cloudmle.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vEeJQT4RLvQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train Fashion MNIST Image Classification with Distributed TensorFlow on Cloud Machine Learning Engine (Cloud MLE)\n",
        "\n",
        "This notebook demonstrates how to use Cloud ML Engine to train a convolutional neural network model for image classification. In the upcoming lab you will deploy the trained model as an Application Programming Interface (API or a web service) for online predictions."
      ]
    },
    {
      "metadata": {
        "id": "9fr0-m0OLvQU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@markdown Enter  your GCP Project ID:\n",
        "PROJECT = \"\" #@param {type: \"string\"}\n",
        "#@markdown Enter  your GCP Storage Bucket ID:\n",
        "BUCKET = \"\" #@param {type: \"string\"}\n",
        "#@markdown OPTIONAL: Replace with your GCP Storage Bucket Region:\n",
        "REGION = \"us-central1\" #@param {type:\"string\"}\n",
        "\n",
        "MODEL_TYPE='cnn_batch_norm'       # convolutional neural network\n",
        "\n",
        "# do not change these\n",
        "os.environ['PROJECT'] = PROJECT\n",
        "os.environ['BUCKET'] = BUCKET\n",
        "os.environ['REGION'] = REGION\n",
        "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
        "os.environ['TFVERSION'] = '1.10'  # Tensorflow version\n",
        "\n",
        "def start_tensorboard(logdir, url_file):\n",
        "  get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(logdir))\n",
        "  get_ipython().system_raw('lt --port 6006 >> {} 2>&1 &'.format(url_file))\n",
        "  get_ipython().system('cat {}'.format(url_file))\n",
        "\n",
        "def stop_tensorboard(url_file):\n",
        "  get_ipython().system_raw(\"ps -Af  | grep -E 'tensorboard|lt --port' | awk '{print $2}' | xargs -I % kill -9 %\")\n",
        "  get_ipython().system_raw(\"rm {}\".format(url_file))\n",
        "\n",
        "try:   \n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()  \n",
        "  print(\"Authenticated\")\n",
        "except:\n",
        "  print(\"Failed to authenticate\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnvI4YTaLvQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/osipov/training-data-analyst.git\n",
        "cp -r training-data-analyst/bootcamps/imagereco/fashionmodel .\n",
        "\n",
        "gcloud config set project $PROJECT\n",
        "gcloud config set compute/region $REGION\n",
        "gsutil -m rm -rf gs://${BUCKET}/fashion/trained_${MODEL_TYPE}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiwZQaA_LvQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train as a Python module on Cloud ML Engine\n",
        "\n",
        "Now since we want to run our code on Cloud ML Engine, we've packaged it as a Python module.\n",
        "\n",
        "The `model.py` and `task.py` files containing the model code are in <a href=\"https://github.com/osipov/training-data-analyst/tree/master/bootcamps/imagereco/fashionmodel/trainer\">fashionmodel/trainer</a>\n",
        "\n",
        "**Next, use Cloud ML Engine so to train on a cluster with ** `--scale-tier=BASIC_GPU`\n",
        "\n",
        "Note that GPU speed up depends on the model type. You'll notice that more complex models train substantially faster on GPUs. When you are working with simple models that take just seconds to minutes to train on a single node, keep in mind that Cloud ML Engine introduces a few minutes of overhead for training job setup & teardown."
      ]
    },
    {
      "metadata": {
        "id": "1GJ6qlJALvQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "OUTDIR=gs://${BUCKET}/fashion/trained_${MODEL_TYPE}\n",
        "JOBNAME=fashion_${MODEL_TYPE}_$(date -u +%y%m%d_%H%M%S)\n",
        "echo $OUTDIR $REGION $JOBNAME\n",
        "gsutil -m rm -rf $OUTDIR\n",
        "gcloud ml-engine jobs submit training $JOBNAME \\\n",
        "   --region=$REGION \\\n",
        "   --module-name=trainer.task \\\n",
        "   --package-path=${PWD}/fashionmodel/trainer \\\n",
        "   --job-dir=$OUTDIR \\\n",
        "   --staging-bucket=gs://$BUCKET \\\n",
        "   --scale-tier=BASIC_GPU \\\n",
        "   --runtime-version=$TFVERSION \\\n",
        "   -- \\\n",
        "   --output_dir=$OUTDIR \\\n",
        "   --train_steps=2395 --learning_rate=0.0029 --train_batch_size=663 \\\n",
        "   --dprob=0.39 --ksize1=5 --nfil1=15 --ksize2=7 --nfil2=20 \\\n",
        "   --model=$MODEL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhKHROlAAjZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the job is queued up for execution on Cloud ML Engine, you should see the output similar to the following:\n",
        "<pre>\n",
        "state: QUEUED\n",
        "CommandException: 1 files/objects could not be removed.\n",
        "Job [fashion_cnn_181125_182110] submitted successfully.\n",
        "Your job is still active. You may view the status of your job with the command\n",
        "\n",
        "  $ gcloud ml-engine jobs describe fashion_cnn_181125_182110\n",
        "\n",
        "or continue streaming the logs with the command\n",
        "\n",
        "  $ gcloud ml-engine jobs stream-logs fashion_cnn_181125_182110\n",
        "</pre>\n",
        "\n",
        "Don't worry if you see a message about files/objects that could not be removed. This message occurs because gsutil mr command tries to remove the output directory for trained model checkpoint files.\n",
        "\n",
        "To monitor the progress of the job from the GCP user interface, navigate to [Jobs](https://console.cloud.google.com/mlengine/jobs) part of the Cloud ML Engine service. Use the \"View Logs\" link to get the details or monitor training details using TensorBoard."
      ]
    },
    {
      "metadata": {
        "id": "VxkgAgP3HwDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitoring training with TensorBoard\n",
        "Notice that TensorBoard is now configured to look in Google Cloud Storage for the model checkpoint files. Run the next cell to launch tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "T1YdOC7bcLme",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "start_tensorboard('gs://{}/fashion/trained_{}'.format(BUCKET, MODEL_TYPE), 'url')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dXyJzwDLvQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%sx read -p 'Press Enter in the input box to stop TensorBoard '\n",
        "stop_tensorboard('url')\n",
        "print(\"Stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ik-w03A6LvRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "</pre>"
      ]
    }
  ]
}