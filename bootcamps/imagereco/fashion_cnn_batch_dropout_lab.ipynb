{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_cnn_batch_dropout_lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_v_915RSIOyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab Exercise: Implement batch normalization and dropout\n",
        "\n",
        "In this notebook you will modify your implementation of a convolutional neural network to include batch normalization and dropout of the dense layer. Next, you will validate the changes in your local environment. The objective of this lab is to improve the accuracy of your model."
      ]
    },
    {
      "metadata": {
        "id": "cAgM-UrtIOyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "MODEL_TYPE='cnn_batch_norm'  #  'cnn_batch_norm' or 'dnn' or 'cnn'\n",
        "\n",
        "# do not change these\n",
        "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
        "\n",
        "def start_tensorboard(logdir, url_file):\n",
        "  get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(logdir))\n",
        "  get_ipython().system_raw('lt --port 6006 >> {} 2>&1 &'.format(url_file))\n",
        "  get_ipython().system('cat {}'.format(url_file))\n",
        "\n",
        "def stop_tensorboard(url_file):\n",
        "  get_ipython().system_raw(\"ps -Af  | grep -E 'tensorboard|lt --port' | awk '{print $2}' | xargs -I % kill -9 %\")\n",
        "  get_ipython().system_raw(\"rm {}\".format(url_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGwumagnIOyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/osipov/training-data-analyst.git\n",
        "cp -r training-data-analyst/bootcamps/imagereco/fashionmodel .\n",
        "find fashionmodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jZqyZnPbIOyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TODO: Add batch normalization to the last dense layer of your CNN**\n",
        "\n",
        "Recall that to implement batch normalization using <code>tf.layers</code> API you need to ensure that the activation function is used after batch normalization is applied to your dense layer. Here's an example of batch normalization of the last dense layer (h3) of the convolutional neural network used in this lab:\n",
        "\n",
        "<pre>\n",
        "  h3 = tf.layers.dense(p2flat, 300, activation=None) #Activation to be added separately after batch normalization\n",
        "\n",
        "  h3 = tf.layers.batch_normalization(h3, \n",
        "             training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "             \n",
        "  h3_batch_normed = tf.nn.relu(h3)\n",
        "</pre>\n",
        "\n",
        "Also, note that <code>mode == tf.estimator.ModeKeys.TRAIN</code> evaluates to <code>True</code> only during model training, so that batch norming is bypassed when the model accuracy is evaluated or used for predictions.\n",
        "\n",
        "Scroll down to the next code cell to find an implementation of the `model.py` file. Add batch normalization as part of your <code>cnn_batch_norm_model</code> method implementation. Return to complete the next TODO."
      ]
    },
    {
      "metadata": {
        "id": "n02Ks0T7IOyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TODO: Add dropout to the batch normed layer of your CNN**\n",
        "\n",
        "Dropout is another feature of the <code>tf.layers</code> library. As with batch normalization, dropout will only be applied during model training. Dropout can be used on a batch normed layer as in the code snippet below:\n",
        "\n",
        "<pre>\n",
        "  h3_with_dropout = tf.layers.dropout(h3_batch_normed,rate=0.1, \n",
        "                                         training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "                    \n",
        "  ylogits = tf.layers.dense(h3_with_dropout, NCLASSES, activation=None)\n",
        "\n",
        "</pre>\n",
        "\n",
        "Scroll down to the next code cell to find an implementation of the `model.py` file. Add dropout to the batched normed layer your implemented in the previous cell in the `cnn_batch_norm_model` method. Finally, execute the next code cell to save your implementation.\n"
      ]
    },
    {
      "metadata": {
        "id": "b_I8M-79I02b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile fashionmodel/trainer/model.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# Licensed under the Apache License, Version 2.0 See footer for details.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "HEIGHT=28\n",
        "WIDTH=28\n",
        "NCLASSES=10\n",
        "\n",
        "def cnn_batch_norm_model(img, mode, hparams):\n",
        "  ksize1 = hparams.get('ksize1', 5)\n",
        "  ksize2 = hparams.get('ksize2', 5)\n",
        "  nfil1 = hparams.get('nfil1', 10)\n",
        "  nfil2 = hparams.get('nfil2', 20)\n",
        "  dprob = hparams.get('dprob', 0.25)\n",
        "  \n",
        "  c1 = tf.layers.conv2d(img, filters=nfil1,\n",
        "                          kernel_size=ksize1, strides=1, # ?x28x28x10\n",
        "                          padding='same', activation=tf.nn.relu)\n",
        "\n",
        "  p1 = tf.layers.max_pooling2d(c1,pool_size=2, strides=2) # ?x14x14x10\n",
        "\n",
        "  c2 = tf.layers.conv2d(p1, filters=nfil2, kernel_size=ksize2, strides=1,\n",
        "                            padding='same', activation=tf.nn.relu) #?x14x14x20\n",
        "\n",
        "  p2 = tf.layers.max_pooling2d(c2, pool_size=2, strides=2) #?x7x7x20\n",
        "  \n",
        "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3] #outlen should be 980\n",
        "  p2flat = tf.reshape(p2, [-1, outlen]) # flattened\n",
        "  \n",
        "  #TODO: create a dense layer and apply batch normalization, \n",
        "  #ensuring that activation is done once, after batch norming\n",
        "\n",
        "  #TODO: apply dropout to the batch normed dense layer  \n",
        "  \n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def cnn_model(img, mode, hparams):\n",
        "  ksize1 = hparams.get('ksize1', 5)\n",
        "  ksize2 = hparams.get('ksize2', 5)\n",
        "  nfil1 = hparams.get('nfil1', 10)\n",
        "  nfil2 = hparams.get('nfil2', 20)\n",
        "  dprob = hparams.get('dprob', 0.25)\n",
        "  \n",
        "  c1 = tf.layers.conv2d(img, filters=nfil1,\n",
        "                          kernel_size=ksize1, strides=1, # ?x28x28x10\n",
        "                          padding='same', activation=tf.nn.relu)\n",
        "\n",
        "  p1 = tf.layers.max_pooling2d(c1,pool_size=2, strides=2) # ?x14x14x10\n",
        "\n",
        "  c2 = tf.layers.conv2d(p1, filters = nfil2, kernel_size = ksize2, strides = 1,\n",
        "                        padding = 'same', activation = tf.nn.relu)\n",
        "  \n",
        "  p2 = tf.layers.max_pooling2d(c2, pool_size = 2, strides = 2)\n",
        "  \n",
        "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3] #outlen should be 980\n",
        "  p2flat = tf.reshape(p2, [-1, outlen]) # flattened\n",
        "  \n",
        "  h3 = tf.layers.dense(p2flat, 300, activation=tf.nn.relu) \n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def dnn_model(img, mode, hparams):\n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) #flatten\n",
        "  h1 = tf.layers.dense(X, 100, activation=tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation=tf.nn.relu)\n",
        "  h3 = tf.layers.dense(h2, 100, activation=tf.nn.relu)\n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def serving_input_fn():\n",
        "    #input will be rank 3\n",
        "    feature_placeholders = {\n",
        "        'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
        "    #but model function requires rank 4\n",
        "    features = {\n",
        "        'image': tf.expand_dims(feature_placeholders['image'],-1)} \n",
        "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
        "\n",
        "def image_classifier(features, labels, mode, params):\n",
        "  model_functions = {\n",
        "      'dnn':dnn_model,\n",
        "      'cnn':cnn_model,\n",
        "      'cnn_batch_norm': cnn_batch_norm_model}\n",
        "  model_function = model_functions[params['model']]  \n",
        "  ylogits, nclasses = model_function(features['image'], mode, params)\n",
        "\n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=ylogits, labels=labels))\n",
        "    evalmetrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # this is needed for batch normalization, but has no effect otherwise\n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "         train_op = tf.contrib.layers.optimize_loss(\n",
        "             loss, \n",
        "             tf.train.get_global_step(),\n",
        "             learning_rate=params['learning_rate'], \n",
        "             optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        " \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={'classes':tf.estimator.export.PredictOutput(\n",
        "            {\"probabilities\": probabilities, \"classes\": classes})}\n",
        "    )\n",
        "\n",
        "def train_and_evaluate(output_dir, hparams):\n",
        "  EVAL_INTERVAL = 60\n",
        "\n",
        "  (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "  train_images = train_images.astype(dtype=np.float32, copy=False).reshape(train_images.shape + (1,))\n",
        "  test_images = test_images.astype(dtype=np.float32, copy=False).reshape(test_images.shape + (1,))\n",
        "  train_labels = np.eye(10)[train_labels]\n",
        "  test_labels = np.eye(10)[test_labels]    \n",
        "    \n",
        "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image': train_images},\n",
        "    y=train_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True,\n",
        "    queue_capacity=5000\n",
        "  )\n",
        "\n",
        "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':test_images},\n",
        "    y=test_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        "    queue_capacity=5000\n",
        "  )\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
        "                                     params = hparams,\n",
        "                                     config=tf.estimator.RunConfig(\n",
        "                                         save_checkpoints_secs = EVAL_INTERVAL),\n",
        "                                     model_dir = output_dir)\n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
        "                                    max_steps = hparams['train_steps'])\n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
        "                                  steps = None,\n",
        "                                  exporters = exporter,\n",
        "                                  throttle_secs = EVAL_INTERVAL)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3v3dqA8iIOyj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run as a Python module\n",
        "\n",
        "You should expect that training will take a bit longer than with the previous lab."
      ]
    },
    {
      "metadata": {
        "id": "qHG5nvvHIOyj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf fashion_trained\n",
        "export PYTHONPATH=${PYTHONPATH}:${PWD}/fashionmodel\n",
        "python -m trainer.task \\\n",
        "   --output_dir=${PWD}/fashion_trained/${MODEL_TYPE} \\\n",
        "   --train_steps=600 \\\n",
        "   --learning_rate=0.01 \\\n",
        "   --train_batch_size=100 \\\n",
        "   --model=$MODEL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kY947TW9IOyq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitoring training with TensorBoard\n",
        "\n",
        "Use this cell to launch tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "UHzD0uHfIOyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "start_tensorboard('./fashion_trained/{}'.format(MODEL_TYPE), 'url')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "da7G_OxhIOyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%sx read -p 'Press Enter in the input box to stop TensorBoard '\n",
        "stop_tensorboard('url')\n",
        "print(\"Stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VvRMRc6IOzC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "</pre>"
      ]
    }
  ]
}