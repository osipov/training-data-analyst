{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_layers_dnn_solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vEeJQT4RLvQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST Image Classification with tf.layers API\n",
        "\n",
        "This notebook demonstrates how to train a deep neural network model for image classification and deploy it as an Application Programming Interface (API) (i.e. web service) for online predictions."
      ]
    },
    {
      "metadata": {
        "id": "9fr0-m0OLvQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# do not change these\n",
        "MODEL_TYPE='dnn'       # deep neural network\n",
        "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
        "\n",
        "def start_tensorboard(logdir, url_file):\n",
        "  get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(logdir))\n",
        "  get_ipython().system_raw('lt --port 6006 >> {} 2>&1 &'.format(url_file))\n",
        "  get_ipython().system('cat {}'.format(url_file))\n",
        "\n",
        "def stop_tensorboard(url_file):\n",
        "  get_ipython().system_raw(\"ps -Af  | grep -E 'tensorboard|lt --port' | awk '{print $2}' | xargs -I % kill -9 %\")\n",
        "  get_ipython().system_raw(\"rm {}\".format(url_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnvI4YTaLvQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/osipov/training-data-analyst.git\n",
        "cp -r training-data-analyst/bootcamps/imagereco/fashionmodel ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLLujkFkQo1N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!find fashionmodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiwZQaA_LvQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run as a Python module\n",
        "\n",
        "Now since we want to run our code on Cloud ML Engine, we've packaged it as a Python module.\n",
        "\n",
        "The `model.py` and `task.py` files containing the model code are in <a href=\"fashionmodel/trainer\">fashionmodel/trainer</a>"
      ]
    },
    {
      "metadata": {
        "id": "sz_wQQJ1lJdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile fashionmodel/trainer/model.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# Licensed under the Apache License, Version 2.0 See footer for details.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "HEIGHT=28\n",
        "WIDTH=28\n",
        "NCLASSES=10\n",
        "\n",
        "def dnn_model(img, mode, hparams):\n",
        "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) #flatten input\n",
        "  h1 = tf.layers.dense(X, 100, activation=tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation=tf.nn.relu)\n",
        "  #TODO: define a tf.layers.dense layer named h3, having h2 layer as input,\n",
        "  #with 100 neurons in the layer and tf.nn.relu activation function \n",
        "  h3 = tf.layers.dense(h2, 100, activation=tf.nn.relu)\n",
        "  \n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES\n",
        "\n",
        "def train_and_evaluate(output_dir, hparams):\n",
        "  EVAL_INTERVAL = 60\n",
        "\n",
        "  (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "  train_images = train_images.astype(dtype=np.float32, copy=False).reshape(train_images.shape + (1,))\n",
        "  test_images = test_images.astype(dtype=np.float32, copy=False).reshape(test_images.shape + (1,))\n",
        "  train_labels = np.eye(10)[train_labels]\n",
        "  test_labels = np.eye(10)[test_labels]    \n",
        "    \n",
        "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image': train_images},\n",
        "    y=train_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True,\n",
        "    queue_capacity=6000\n",
        "  )\n",
        "\n",
        "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':test_images},\n",
        "    y=test_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=1,\n",
        "    shuffle=False,\n",
        "    queue_capacity=6000\n",
        "  )\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
        "                                     params = hparams,\n",
        "                                     config=tf.estimator.RunConfig(\n",
        "                                         save_checkpoints_secs = EVAL_INTERVAL),\n",
        "                                     model_dir = output_dir)\n",
        "  \n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
        "                                    max_steps = hparams['train_steps'])\n",
        "  \n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  \n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
        "                                  steps = None,\n",
        "                                  exporters = exporter,\n",
        "                                  throttle_secs = EVAL_INTERVAL)\n",
        "  \n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "  \n",
        "def serving_input_fn():\n",
        "    #input will be rank 3\n",
        "    feature_placeholders = {\n",
        "        'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
        "    \n",
        "    #but model function requires rank 4\n",
        "    features = {\n",
        "        'image': tf.expand_dims(feature_placeholders['image'], -1)} \n",
        "    \n",
        "    return tf.estimator.export.ServingInputReceiver(features, \n",
        "                                                    feature_placeholders)\n",
        "\n",
        "def image_classifier(features, labels, mode, params):\n",
        "  model_functions = {\n",
        "      'dnn':dnn_model}\n",
        "  \n",
        "  model_function = model_functions[params['model']]  \n",
        "  \n",
        "  ylogits, nclasses = model_function(features['image'], mode, params)\n",
        "\n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  \n",
        "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=ylogits, labels=labels))\n",
        "    \n",
        "    evalmetrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # this is needed for batch normalization, but has no effect otherwise\n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "         train_op = tf.contrib.layers.optimize_loss(\n",
        "             loss, \n",
        "             tf.train.get_global_step(),\n",
        "             learning_rate=params['learning_rate'], \n",
        "             optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "      \n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        " \n",
        "  return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={'classes':tf.estimator.export.PredictOutput(\n",
        "            {\"probabilities\": probabilities, \"classes\": classes})}\n",
        "    )\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSzWpku4LvQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf fashion_trained\n",
        "export PYTHONPATH=${PYTHONPATH}:${PWD}/fashionmodel\n",
        "python -m trainer.task \\\n",
        "   --output_dir=${PWD}/fashion_trained/${MODEL_TYPE} \\\n",
        "   --train_steps=1000 \\\n",
        "   --learning_rate=0.01 \\\n",
        "   --train_batch_size=143 \\\n",
        "   --model=$MODEL_TYPE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USDJ8fRQLvQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training should finish in just a few seconds because it ran outside of the Jupyter's runtime, as an independent process of the node's operating system. You can explore the training metrics using TensorBoard."
      ]
    },
    {
      "metadata": {
        "id": "cMi3UKzrFt56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monitoring training with TensorBoard\n",
        "\n",
        "Use this cell to launch tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "-B17C-a1LvQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "start_tensorboard('./fashion_trained/{}'.format(MODEL_TYPE), 'url')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtsxDW_yOBIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%sx read -p 'Press Enter in the input box to stop TensorBoard '\n",
        "stop_tensorboard('url')\n",
        "print(\"Stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ik-w03A6LvRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "</pre>"
      ]
    }
  ]
}